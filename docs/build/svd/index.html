<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>SVD · AdvChemStat.jl</title><meta name="title" content="SVD · AdvChemStat.jl"/><meta property="og:title" content="SVD · AdvChemStat.jl"/><meta property="twitter:title" content="SVD · AdvChemStat.jl"/><meta name="description" content="Documentation for AdvChemStat.jl."/><meta property="og:description" content="Documentation for AdvChemStat.jl."/><meta property="twitter:description" content="Documentation for AdvChemStat.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="AdvChemStat.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">AdvChemStat.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>SVD</a><ul class="internal"><li><a class="tocitem" href="#Introduction"><span>Introduction</span></a></li><li><a class="tocitem" href="#How?"><span>How?</span></a></li><li><a class="tocitem" href="#Practical-Example"><span>Practical Example</span></a></li><li><a class="tocitem" href="#Applications"><span>Applications</span></a></li><li><a class="tocitem" href="#Additional-Example"><span>Additional Example</span></a></li></ul></li><li><a class="tocitem" href="../HCA/">HCA</a></li><li><a class="tocitem" href="../KMeans/">K-Means</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>SVD</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>SVD</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/EMCMS/AdvChemStat.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/EMCMS/AdvChemStat.jl/blob/main/docs/src/svd.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Singular-Value-Decomposition-(SVD)"><a class="docs-heading-anchor" href="#Singular-Value-Decomposition-(SVD)">Singular Value Decomposition (SVD)</a><a id="Singular-Value-Decomposition-(SVD)-1"></a><a class="docs-heading-anchor-permalink" href="#Singular-Value-Decomposition-(SVD)" title="Permalink"></a></h1><h2 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h2><p>The <a href="https://en.wikipedia.org/wiki/Singular_value_decomposition"><strong>SVD</strong></a> is a matrix factorization technique that decomposes any matrix to a unique set of matrices. The <strong>SVD</strong> is used for dimension reduction, trend analysis, and potentially for the clustering of a multivariate dataset. <strong>SVD</strong> is an exploratory approach to the data analysis and therefore it is an unsupervised approach. In other words, you will only need the <em>X</em> block matrix. However, where the <em>Y</em> matrix/vector is available, it (i.e. <em>Y</em>) can be used for building composite models or assess the quality of the clustering. </p><h2 id="How?"><a class="docs-heading-anchor" href="#How?">How?</a><a id="How?-1"></a><a class="docs-heading-anchor-permalink" href="#How?" title="Permalink"></a></h2><p>In <strong>SVD</strong> the matrix <em><span>$X_{m \times n}$</span></em> is decomposed into the matrices <em><span>$U_{m \times n}$</span></em>, <em><span>$D_{n \times n}$</span></em>, and <em><span>$V_{n \times n}^{T}$</span></em>. The matrix <em><span>$U_{m \times n}$</span></em> is the left singular matrix and it represents a rotation in the matrix space. The <em><span>$D_{n \times n}$</span></em> is diagonal matrix and contains the singular values. This matrix may be indicated with different symbols such as <em><span>$\Sigma_{n \times n}$</span></em>. The <em><span>$D_{n \times n}$</span></em> matrix in the geometrical space represents an act of stretching. Each <em>singular value</em> is the degree and/or weight of stretching. We use the notation <em><span>$D_{n \times n}$</span></em> to remind ourselves that this is a diagonal matrix. Finally, <em><span>$V_{n \times n}^{T}$</span></em> is called the right singular matrix and is associated with rotation. Overall, <strong>SVD</strong> geometrically is a combination of a rotation, a stretching, and a second rotation.</p><p>The two matrices <em><span>$U_{m \times n}$</span></em> and <em><span>$V_{n \times n}^{T}$</span></em> are very special due to their <a href="https://en.wikipedia.org/wiki/Unitary_matrix">unitary</a> properties.</p><p class="math-container">\[
U^{T} \times U = U \times U^{T} = I\\
V^{T} \times V = V \times V^{T} = I
\]</p><p>Therefore the general matrix expression of <strong>SVD</strong> is the following: </p><p class="math-container">\[X = UDV^{T}.
\]</p><p>To deal with the non-square matrices, we have to convert our <em>X</em> matrix to <span>$X^{T} \times X$</span>. This implies that our <strong>SVD</strong> equation will become the following: </p><p class="math-container">\[X^{T}X = (UDV^{T})^{T} \times UDV^{T}.
\]</p><p>And after a little bit of linear algebra: </p><p class="math-container">\[X^{T}X = VD^{T} \times DV^{T} \\ 
and \\

XV = UD.
\]</p><p>This is a system of two equations with two variables that can be solved. Before looking at an example of such system let&#39;s remind ourselves that <span>$VD^{T} \times DV^{T}$</span> is the solution of <a href="https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix">eigenvalue/eigenvector decomposition</a> of <span>$X^{T}X$</span>. This means that both <em>D</em> and <em><span>$V^{T}$</span></em> can be calculated by calculating the <a href="https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors">eigenvalues and eigenvectors</a> of <span>$X^{T}X$</span>. Therefore we can calculate <em>D</em> and <em>V</em> as follows:</p><p class="math-container">\[
D = \sqrt{eigenvalues(X^{T}X)}\\ 
V = eigenvector(X^{T}X).
\]</p><p>Once we know <em>V</em>, we can use that and the second equation of SVD to calculate the last part i.e. the matrix <em>U</em>. </p><p class="math-container">\[U = XVD^{-1} 
\]</p><p>Please note that <span>$D^{-1}$</span> denotes the <a href="https://en.wikipedia.org/wiki/Invertible_matrix">inverse or pseudo-inverse</a> of the matrix <em>D</em>.  </p><h2 id="Practical-Example"><a class="docs-heading-anchor" href="#Practical-Example">Practical Example</a><a id="Practical-Example-1"></a><a class="docs-heading-anchor-permalink" href="#Practical-Example" title="Permalink"></a></h2><p>Let&#39;s do the <strong>SVD</strong> calculations together for the below matrix: </p><pre><code class="language-julia hljs">using AdvChemStat

X = [5 -5;-1 7;1 10]</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">3×2 Matrix{Int64}:
  5  -5
 -1   7
  1  10</code></pre><h3 id="Step-1:-X{T}X"><a class="docs-heading-anchor" href="#Step-1:-X{T}X">Step 1: <span>$X^{T}X$</span></a><a id="Step-1:-X{T}X-1"></a><a class="docs-heading-anchor-permalink" href="#Step-1:-X{T}X" title="Permalink"></a></h3><pre><code class="language-julia hljs"># The function transpose(-) is part of LinearAlgebra.jl package that has been automatically installed via AdvChemStat.jl package.
# Not all the functions of LinearAlgebra.jl are exported within the AdvChemStat.jl environment.
XtX = transpose(X)*X</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2×2 Matrix{Int64}:
  27  -22
 -22  174</code></pre><h3 id="Step-2:-Calculation-of-*D*,-*V*,-and-*U*"><a class="docs-heading-anchor" href="#Step-2:-Calculation-of-*D*,-*V*,-and-*U*">Step 2: Calculation of <em>D</em>, <em>V</em>, and <em>U</em></a><a id="Step-2:-Calculation-of-*D*,-*V*,-and-*U*-1"></a><a class="docs-heading-anchor-permalink" href="#Step-2:-Calculation-of-*D*,-*V*,-and-*U*" title="Permalink"></a></h3><pre><code class="language-julia hljs">D = diagm(sqrt.(eigvals(XtX))) # A diagonal matrix is generated</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2×2 Matrix{Float64}:
 4.87628   0.0
 0.0      13.3125</code></pre><pre><code class="language-julia hljs">V = eigvecs(XtX) # Right singular matrix</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2×2 Matrix{Float64}:
 -0.989446  -0.144904
 -0.144904   0.989446</code></pre><pre><code class="language-julia hljs">U = X*V*pinv(D)	# Left singular matrix</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">3×2 Matrix{Float64}:
 -0.865969    -0.426048
 -0.00510321   0.531158
 -0.500072     0.732362</code></pre><h4 id="Builtin-Function"><a class="docs-heading-anchor" href="#Builtin-Function">Builtin Function</a><a id="Builtin-Function-1"></a><a class="docs-heading-anchor-permalink" href="#Builtin-Function" title="Permalink"></a></h4><p>The same calculations can be done with the function <em>svd(-)</em> of AdvChemStat package provided via LinearAlgebra.jl package. </p><pre><code class="language-julia hljs"> out = svd(X)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">LinearAlgebra.SVD{Float64, Float64, Matrix{Float64}}
U factor:
3×2 Matrix{Float64}:
  0.426048  0.865969
 -0.531158  0.00510321
 -0.732362  0.500072
singular values:
2-element Vector{Float64}:
 13.312471610995619
  4.8762792789621585
Vt factor:
2×2 Matrix{Float64}:
 0.144904  -0.989446
 0.989446   0.144904</code></pre><pre><code class="language-julia hljs"> D = diagm(out.S) # The singular value matrix</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2×2 Matrix{Float64}:
 13.3125  0.0
  0.0     4.87628</code></pre><pre><code class="language-julia hljs"> U = out.U # Left singular matrix</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">3×2 Matrix{Float64}:
  0.426048  0.865969
 -0.531158  0.00510321
 -0.732362  0.500072</code></pre><pre><code class="language-julia hljs"> V = transpose(out.Vt) # Right singular matrix</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2×2 transpose(::Matrix{Float64}) with eltype Float64:
  0.144904  0.989446
 -0.989446  0.144904</code></pre><p>Please note that the builtin function sorts the singular values in descending order and consequently the other two matrices are also sorted following the same. Additionally, for ease of calculations the builtin function generates the mirror image of the <em>U</em> and <em>V</em> matrices. These differences essentially do not impact your calculations at all, as long as they are limited to what is listed above.</p><h3 id="Step-3-Calculation-of-\\hat{X}"><a class="docs-heading-anchor" href="#Step-3-Calculation-of-\\hat{X}">Step 3 Calculation of <span>$\hat{X}$</span></a><a id="Step-3-Calculation-of-\\hat{X}-1"></a><a class="docs-heading-anchor-permalink" href="#Step-3-Calculation-of-\\hat{X}" title="Permalink"></a></h3><p>Using both the manual method and the builtin function, you can calculate <span>$\hat{X}$</span> following the below operation. </p><pre><code class="language-julia hljs">X_hat = U*D*transpose(V)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">3×2 Matrix{Float64}:
  5.0  -5.0
 -1.0   7.0
  1.0  10.0</code></pre><h2 id="Applications"><a class="docs-heading-anchor" href="#Applications">Applications</a><a id="Applications-1"></a><a class="docs-heading-anchor-permalink" href="#Applications" title="Permalink"></a></h2><p>As mentioned above <strong>SVD</strong> has several applications in different fields. Here we will focus on three, namely: dimension reduction, clustering/trend analysis, and multivariate regression. This dataset contains five variables (i.e. columns) and 150 measurements (i.e. rows). The last variable &quot;Species&quot; is a categorical variable which defines the flower species. </p><h3 id="Dimension-Reduction"><a class="docs-heading-anchor" href="#Dimension-Reduction">Dimension Reduction</a><a id="Dimension-Reduction-1"></a><a class="docs-heading-anchor-permalink" href="#Dimension-Reduction" title="Permalink"></a></h3><p>To show case the power of <strong>SVD</strong> in dimension reduction we will use the <em>Iris</em> dataset from <a href="https://github.com/JuliaStats/RDatasets.jl">Rdatasets</a>. </p><pre><code class="language-julia hljs">using AdvChemStat

data = dataset(&quot;datasets&quot;, &quot;iris&quot;)
describe(data) # Summarizes the dataset</code></pre><div><div style = "float: left;"><span>5×7 DataFrame</span></div><div style = "clear: both;"></div></div><div class = "data-frame" style = "overflow-x: scroll;"><table class = "data-frame" style = "margin-bottom: 6px;"><thead><tr class = "header"><th class = "rowNumber" style = "font-weight: bold; text-align: right;">Row</th><th style = "text-align: left;">variable</th><th style = "text-align: left;">mean</th><th style = "text-align: left;">min</th><th style = "text-align: left;">median</th><th style = "text-align: left;">max</th><th style = "text-align: left;">nmissing</th><th style = "text-align: left;">eltype</th></tr><tr class = "subheader headerLastRow"><th class = "rowNumber" style = "font-weight: bold; text-align: right;"></th><th title = "Symbol" style = "text-align: left;">Symbol</th><th title = "Union{Nothing, Float64}" style = "text-align: left;">Union…</th><th title = "Any" style = "text-align: left;">Any</th><th title = "Union{Nothing, Float64}" style = "text-align: left;">Union…</th><th title = "Any" style = "text-align: left;">Any</th><th title = "Int64" style = "text-align: left;">Int64</th><th title = "DataType" style = "text-align: left;">DataType</th></tr></thead><tbody><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">1</td><td style = "text-align: left;">SepalLength</td><td style = "text-align: left;">5.84333</td><td style = "text-align: left;">4.3</td><td style = "text-align: left;">5.8</td><td style = "text-align: left;">7.9</td><td style = "text-align: right;">0</td><td style = "text-align: left;">Float64</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">2</td><td style = "text-align: left;">SepalWidth</td><td style = "text-align: left;">3.05733</td><td style = "text-align: left;">2.0</td><td style = "text-align: left;">3.0</td><td style = "text-align: left;">4.4</td><td style = "text-align: right;">0</td><td style = "text-align: left;">Float64</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">3</td><td style = "text-align: left;">PetalLength</td><td style = "text-align: left;">3.758</td><td style = "text-align: left;">1.0</td><td style = "text-align: left;">4.35</td><td style = "text-align: left;">6.9</td><td style = "text-align: right;">0</td><td style = "text-align: left;">Float64</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">4</td><td style = "text-align: left;">PetalWidth</td><td style = "text-align: left;">1.19933</td><td style = "text-align: left;">0.1</td><td style = "text-align: left;">1.3</td><td style = "text-align: left;">2.5</td><td style = "text-align: right;">0</td><td style = "text-align: left;">Float64</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">5</td><td style = "text-align: left;">Species</td><td style = "font-style: italic; text-align: left;"></td><td style = "text-align: left;">setosa</td><td style = "font-style: italic; text-align: left;"></td><td style = "text-align: left;">virginica</td><td style = "text-align: right;">0</td><td style = "text-align: left;">CategoricalValue{String, UInt8}</td></tr></tbody></table></div><p>Here we show how <strong>SVD</strong> is used for dimension reduction with the <em>iris</em> dataset. First we need to convert the dataset from table (i.e. <a href="https://dataframes.juliadata.org/stable/">dataframe</a>) to a matrix. For data we can use the function <em>Matrix(-)</em> builtin in the julia core language.</p><pre><code class="language-julia hljs">Y = data[!,&quot;Species&quot;]
X = Matrix(data[:,1:4]); # The first four columns are selected for this</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">150×4 Matrix{Float64}:
 5.1  3.5  1.4  0.2
 4.9  3.0  1.4  0.2
 4.7  3.2  1.3  0.2
 4.6  3.1  1.5  0.2
 5.0  3.6  1.4  0.2
 5.4  3.9  1.7  0.4
 4.6  3.4  1.4  0.3
 5.0  3.4  1.5  0.2
 4.4  2.9  1.4  0.2
 4.9  3.1  1.5  0.1
 ⋮              
 6.9  3.1  5.1  2.3
 5.8  2.7  5.1  1.9
 6.8  3.2  5.9  2.3
 6.7  3.3  5.7  2.5
 6.7  3.0  5.2  2.3
 6.3  2.5  5.0  1.9
 6.5  3.0  5.2  2.0
 6.2  3.4  5.4  2.3
 5.9  3.0  5.1  1.8</code></pre><p>Now we can perform <strong>SVD</strong> on the <em>X</em> and try to assess the underlying trends in the data. </p><pre><code class="language-julia hljs"> out = svd(X)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">LinearAlgebra.SVD{Float64, Float64, Matrix{Float64}}
U factor:
150×4 Matrix{Float64}:
 -0.0616168   0.129611    0.0021386    0.00163819
 -0.0580709   0.11102     0.0706724    0.051757
 -0.056763    0.117966    0.00434255   0.00955702
 -0.0566534   0.105308    0.00592467  -0.0416439
 -0.0612302   0.13109    -0.0318811   -0.0322148
 -0.0675032   0.130885   -0.0685372   -0.0113642
 -0.0574821   0.116598   -0.0664137   -0.0267434
 -0.0609726   0.120943    0.00543027  -0.0240567
 -0.0537612   0.0999415   0.0176366   -0.0165154
 -0.0588267   0.112043    0.0649689   -0.030472
  ⋮                                   
 -0.0975766  -0.0421663  -0.0477535    0.269324
 -0.0866823  -0.0643397  -0.0672473   -0.0101401
 -0.101467   -0.0726079  -0.0954496    0.0314228
 -0.100361   -0.0670195  -0.157083     0.128363
 -0.0961497  -0.0524346  -0.0589711    0.226609
 -0.0892692  -0.0585064   0.0460294    0.134135
 -0.0940593  -0.0498297  -0.04144      0.0728945
 -0.0948896  -0.0561012  -0.212978     0.0231635
 -0.0884784  -0.0515697  -0.0957528   -0.0835063
singular values:
4-element Vector{Float64}:
 95.95991387196452
 17.761033657328568
  3.4609309303869726
  1.884826305918045
Vt factor:
4×4 Matrix{Float64}:
 -0.751108  -0.380086  -0.513009   -0.167908
  0.284175   0.546745  -0.708665   -0.343671
  0.502155  -0.675243  -0.0591662  -0.537016
  0.320814  -0.317256  -0.480745    0.751872</code></pre><pre><code class="language-julia hljs"> D = diagm(out.S) # The singular value matrix</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">4×4 Matrix{Float64}:
 95.9599   0.0    0.0      0.0
  0.0     17.761  0.0      0.0
  0.0      0.0    3.46093  0.0
  0.0      0.0    0.0      1.88483</code></pre><pre><code class="language-julia hljs"> U = out.U # Left singular matrix</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">150×4 Matrix{Float64}:
 -0.0616168   0.129611    0.0021386    0.00163819
 -0.0580709   0.11102     0.0706724    0.051757
 -0.056763    0.117966    0.00434255   0.00955702
 -0.0566534   0.105308    0.00592467  -0.0416439
 -0.0612302   0.13109    -0.0318811   -0.0322148
 -0.0675032   0.130885   -0.0685372   -0.0113642
 -0.0574821   0.116598   -0.0664137   -0.0267434
 -0.0609726   0.120943    0.00543027  -0.0240567
 -0.0537612   0.0999415   0.0176366   -0.0165154
 -0.0588267   0.112043    0.0649689   -0.030472
  ⋮                                   
 -0.0975766  -0.0421663  -0.0477535    0.269324
 -0.0866823  -0.0643397  -0.0672473   -0.0101401
 -0.101467   -0.0726079  -0.0954496    0.0314228
 -0.100361   -0.0670195  -0.157083     0.128363
 -0.0961497  -0.0524346  -0.0589711    0.226609
 -0.0892692  -0.0585064   0.0460294    0.134135
 -0.0940593  -0.0498297  -0.04144      0.0728945
 -0.0948896  -0.0561012  -0.212978     0.0231635
 -0.0884784  -0.0515697  -0.0957528   -0.0835063</code></pre><pre><code class="language-julia hljs"> V = transpose(out.Vt) # Right singular matrix</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">4×4 transpose(::Matrix{Float64}) with eltype Float64:
 -0.751108   0.284175   0.502155    0.320814
 -0.380086   0.546745  -0.675243   -0.317256
 -0.513009  -0.708665  -0.0591662  -0.480745
 -0.167908  -0.343671  -0.537016    0.751872</code></pre><p>As you may have noticed, there are four variables in the original data and four non-zero singular values. Each column in the lift singular matrix is associated with one singular value and one row in the <em>V</em> matrix. For example the first column of sorted <em>U</em> matrix (i.e. via the builtin function) is directly connected to the first singular value of 95.9 and the first row of the matrix <em>V</em>. With all four singular values we can describe 100% of variance in the data (i.e. <span>$\hat{X} = X$</span>). By removing the smaller or less important singular values we can reduce the number of dimensions in the data. We can calculate the variance explained by each singular value via two different approaches. </p><pre><code class="language-julia hljs"> var_exp = diag(D) ./ sum(D) # diag() selects the diagonal values in a matrix</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">4-element Vector{Float64}:
 0.8059340691495326
 0.14916876798004958
 0.029067159767294896
 0.015830003103122974</code></pre><pre><code class="language-julia hljs"> var_exp_cum = cumsum(diag(D)) ./ sum(D) # cumsum() calculates the cumulative sum</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">4-element Vector{Float64}:
 0.8059340691495326
 0.9551028371295821
 0.9841699968968771
 1.0</code></pre><pre><code class="language-julia hljs"> scatter(1:length(var_exp),var_exp,label=&quot;Individual&quot;)
 plot!(1:length(var_exp),var_exp,label=false)

 scatter!(1:length(var_exp),var_exp_cum,label=&quot;Cumulative&quot;)
 plot!(1:length(var_exp),var_exp_cum,label=false)
 xlabel!(&quot;Nr Singular Values&quot;)
 ylabel!(&quot;Variance Explained&quot;)</code></pre><img src="3e64eeae.svg" alt="Example block output"/><p>Given that the first two singular values explain more than 95% variance in the data, they are considered enough for modeling our dataset. The next step here is to first plot the scores (i.e. the left singular matrix) of first and second singular values against each other to see whether we have a model or not. Each column in the <em><span>$U$</span></em> matrix represents a set of scores associated with a singular value (e.g. first column for the first singular value).</p><pre><code class="language-julia hljs"> scatter(U[:,1],U[:,2],label=false)
 xlabel!(&quot;First Singular value (81%)&quot;)
 ylabel!(&quot;Second Singular value (15%)&quot;)</code></pre><img src="75ec206d.svg" alt="Example block output"/><p>At this point we are assuming that we do not have any idea about the plant species included in our dataset. Now we need to connect the singular values to individual variables. For that similarly to <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">PCA</a> we will take advantage of the loadings, which in this case are the columns of the <em><span>$V$</span></em> or the rows of <em><span>$V^{T}$</span></em>. </p><pre><code class="language-julia hljs"> bar(V[:,1] ./ sum(abs.(V)),label=&quot;First SV&quot;)
 bar!(V[:,2] ./ sum(abs.(V)),label=&quot;Second SV&quot;)
 xlabel!(&quot;Variable Nr&quot;)
 ylabel!(&quot;Importance&quot;)
 #ylims!(-0.1,0.1)</code></pre><img src="23949720.svg" alt="Example block output"/><p>The sign of each loading value shows the relationship between the variable and the model. For example, based on the first <em>SV</em> the variable number one and two both have a negative impact on the final model (i.e. scores of the <em>SV1</em>). A positive impact indicates an increase of the final model scores with the variable while a negative impact means a decrease in the score values with an increase the variable. </p><pre><code class="language-julia hljs"> p1 = scatter(X[:,1],U[:,1],label=false)
 xlabel!(&quot;SepalLength&quot;)
 ylabel!(&quot;Scores U1&quot;)

  p2 = scatter(X[:,2],U[:,1],label=false)
 xlabel!(&quot;SepalWidth&quot;)
 ylabel!(&quot;Scores U1&quot;)

  p3 = scatter(X[:,2],U[:,2],label=false)
 xlabel!(&quot;SepalWidth&quot;)
 ylabel!(&quot;Scores U2&quot;)

 p4 = scatter(X[:,3],U[:,2],label=false)
 xlabel!(&quot;PetalLength&quot;)
 ylabel!(&quot;Scores U2&quot;)

 plot(p1,p2,p3,p4,layout = (2,2))</code></pre><img src="3084db1b.svg" alt="Example block output"/><p>In this particular case, the <em>SV1</em> is a linear combination of <em>SepalLength</em> and <em>SepalWidth</em> while the <em>SV2</em> is a linear combination of all four variables. This implies that we can cover the variance present in the <span>$X$</span> with two variables, which are <span>$U1$</span> and <span>$U2$</span>. For this dataset, we have a reduction of variables from 4 to 2, which may not look impressive. However, this can be a very useful technique when dealing with a large number of variables (the octane example).</p><h3 id="Clustering"><a class="docs-heading-anchor" href="#Clustering">Clustering</a><a id="Clustering-1"></a><a class="docs-heading-anchor-permalink" href="#Clustering" title="Permalink"></a></h3><p>When we perform cluster analysis or most modeling approaches, we need to divide our data into training and test sets. We usually go for a division of 80% for training set and 20% for the test. More details are provided in the cross-validation chapter. Let&#39;s randomly select 15 data points to put aside as the test set. </p><pre><code class="language-julia hljs">n = 15 # number of points to be selected

rand_ind = rand(1:size(X,1),n) # generate a set of random numbers between 1 and size(X,1)
ind_tr = ones(size(X,1))       # generate a matrix of indices
ind_tr[rand_ind] .= 0          # set the test set values&#39; indices to zero
X_tr = X[ind_tr .== 1,:]       # select the training set
X_ts = X[rand_ind,:]           # select the test set
data[rand_ind,:]</code></pre><div><div style = "float: left;"><span>15×5 DataFrame</span></div><div style = "clear: both;"></div></div><div class = "data-frame" style = "overflow-x: scroll;"><table class = "data-frame" style = "margin-bottom: 6px;"><thead><tr class = "header"><th class = "rowNumber" style = "font-weight: bold; text-align: right;">Row</th><th style = "text-align: left;">SepalLength</th><th style = "text-align: left;">SepalWidth</th><th style = "text-align: left;">PetalLength</th><th style = "text-align: left;">PetalWidth</th><th style = "text-align: left;">Species</th></tr><tr class = "subheader headerLastRow"><th class = "rowNumber" style = "font-weight: bold; text-align: right;"></th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "CategoricalArrays.CategoricalValue{String, UInt8}" style = "text-align: left;">Cat…</th></tr></thead><tbody><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">1</td><td style = "text-align: right;">6.8</td><td style = "text-align: right;">3.0</td><td style = "text-align: right;">5.5</td><td style = "text-align: right;">2.1</td><td style = "text-align: left;">virginica</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">2</td><td style = "text-align: right;">4.9</td><td style = "text-align: right;">2.5</td><td style = "text-align: right;">4.5</td><td style = "text-align: right;">1.7</td><td style = "text-align: left;">virginica</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">3</td><td style = "text-align: right;">5.0</td><td style = "text-align: right;">3.5</td><td style = "text-align: right;">1.6</td><td style = "text-align: right;">0.6</td><td style = "text-align: left;">setosa</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">4</td><td style = "text-align: right;">7.6</td><td style = "text-align: right;">3.0</td><td style = "text-align: right;">6.6</td><td style = "text-align: right;">2.1</td><td style = "text-align: left;">virginica</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">5</td><td style = "text-align: right;">5.0</td><td style = "text-align: right;">2.3</td><td style = "text-align: right;">3.3</td><td style = "text-align: right;">1.0</td><td style = "text-align: left;">versicolor</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">6</td><td style = "text-align: right;">4.4</td><td style = "text-align: right;">3.2</td><td style = "text-align: right;">1.3</td><td style = "text-align: right;">0.2</td><td style = "text-align: left;">setosa</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">7</td><td style = "text-align: right;">6.5</td><td style = "text-align: right;">3.0</td><td style = "text-align: right;">5.8</td><td style = "text-align: right;">2.2</td><td style = "text-align: left;">virginica</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">8</td><td style = "text-align: right;">6.4</td><td style = "text-align: right;">3.2</td><td style = "text-align: right;">4.5</td><td style = "text-align: right;">1.5</td><td style = "text-align: left;">versicolor</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">9</td><td style = "text-align: right;">5.0</td><td style = "text-align: right;">2.0</td><td style = "text-align: right;">3.5</td><td style = "text-align: right;">1.0</td><td style = "text-align: left;">versicolor</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">10</td><td style = "text-align: right;">5.9</td><td style = "text-align: right;">3.0</td><td style = "text-align: right;">4.2</td><td style = "text-align: right;">1.5</td><td style = "text-align: left;">versicolor</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">11</td><td style = "text-align: right;">5.4</td><td style = "text-align: right;">3.0</td><td style = "text-align: right;">4.5</td><td style = "text-align: right;">1.5</td><td style = "text-align: left;">versicolor</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">12</td><td style = "text-align: right;">5.8</td><td style = "text-align: right;">2.6</td><td style = "text-align: right;">4.0</td><td style = "text-align: right;">1.2</td><td style = "text-align: left;">versicolor</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">13</td><td style = "text-align: right;">4.8</td><td style = "text-align: right;">3.4</td><td style = "text-align: right;">1.9</td><td style = "text-align: right;">0.2</td><td style = "text-align: left;">setosa</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">14</td><td style = "text-align: right;">7.7</td><td style = "text-align: right;">3.8</td><td style = "text-align: right;">6.7</td><td style = "text-align: right;">2.2</td><td style = "text-align: left;">virginica</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">15</td><td style = "text-align: right;">4.5</td><td style = "text-align: right;">2.3</td><td style = "text-align: right;">1.3</td><td style = "text-align: right;">0.3</td><td style = "text-align: left;">setosa</td></tr></tbody></table></div><p>Now that we have training and test sets separated, we can build our model using the training set. This implies that the model has never seen the values in the test set. It should be noted that we always want the homogenous distribution of measurements in the test set. Also, each iteration here will result in a different test set as a new set of random numbers are generated.  Now let&#39;s build our model with only the <span>$X_{tr}$</span> following the same procedure as before. </p><pre><code class="language-julia hljs"> out = svd(X_tr)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">LinearAlgebra.SVD{Float64, Float64, Matrix{Float64}}
U factor:
135×4 Matrix{Float64}:
 -0.06506     0.133138    0.00247777   0.00353554
 -0.0613098   0.113888    0.0731112    0.0630303
 -0.059934    0.121159    0.00455064   0.0120504
 -0.0598086   0.108045    0.00744537  -0.0429496
 -0.0646523   0.134703   -0.0323884   -0.0357454
 -0.0712653   0.134367   -0.0716032   -0.0169444
 -0.0606891   0.119763   -0.0689388   -0.033295
 -0.0643742   0.124167    0.0065443   -0.0238826
 -0.0567558   0.102528    0.0190938   -0.0150401
 -0.0621063   0.114958    0.0692863   -0.0255138
  ⋮                                   
 -0.102849   -0.0458498  -0.0594011    0.279984
 -0.0913432  -0.0685339  -0.0725487   -0.02123
 -0.106925   -0.0774221  -0.103642     0.0200475
 -0.105762   -0.0716046  -0.170963     0.11841
 -0.101336   -0.0564541  -0.0701485    0.233007
 -0.0940789  -0.0626231   0.0427973    0.143589
 -0.0991331  -0.0536724  -0.0475789    0.0701706
 -0.0999995  -0.0601129  -0.226771     0.00116117
 -0.0932447  -0.0552945  -0.100492    -0.102078
singular values:
4-element Vector{Float64}:
 91.01413993356265
 17.123083643788487
  3.2868266835163293
  1.7587236946802938
Vt factor:
4×4 Matrix{Float64}:
 -0.75263   -0.381585  -0.510059   -0.166679
  0.279547   0.547439  -0.709256   -0.345137
  0.486908  -0.659083  -0.0385151  -0.57188
  0.343981  -0.346862  -0.48509     0.725294</code></pre><pre><code class="language-julia hljs"> D = diagm(out.S) # The singular value matrix</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">4×4 Matrix{Float64}:
 91.0141   0.0     0.0      0.0
  0.0     17.1231  0.0      0.0
  0.0      0.0     3.28683  0.0
  0.0      0.0     0.0      1.75872</code></pre><pre><code class="language-julia hljs"> U = out.U # Left singular matrix</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">135×4 Matrix{Float64}:
 -0.06506     0.133138    0.00247777   0.00353554
 -0.0613098   0.113888    0.0731112    0.0630303
 -0.059934    0.121159    0.00455064   0.0120504
 -0.0598086   0.108045    0.00744537  -0.0429496
 -0.0646523   0.134703   -0.0323884   -0.0357454
 -0.0712653   0.134367   -0.0716032   -0.0169444
 -0.0606891   0.119763   -0.0689388   -0.033295
 -0.0643742   0.124167    0.0065443   -0.0238826
 -0.0567558   0.102528    0.0190938   -0.0150401
 -0.0621063   0.114958    0.0692863   -0.0255138
  ⋮                                   
 -0.102849   -0.0458498  -0.0594011    0.279984
 -0.0913432  -0.0685339  -0.0725487   -0.02123
 -0.106925   -0.0774221  -0.103642     0.0200475
 -0.105762   -0.0716046  -0.170963     0.11841
 -0.101336   -0.0564541  -0.0701485    0.233007
 -0.0940789  -0.0626231   0.0427973    0.143589
 -0.0991331  -0.0536724  -0.0475789    0.0701706
 -0.0999995  -0.0601129  -0.226771     0.00116117
 -0.0932447  -0.0552945  -0.100492    -0.102078</code></pre><pre><code class="language-julia hljs"> V = transpose(out.Vt) # Right singular matrix</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">4×4 transpose(::Matrix{Float64}) with eltype Float64:
 -0.75263    0.279547   0.486908    0.343981
 -0.381585   0.547439  -0.659083   -0.346862
 -0.510059  -0.709256  -0.0385151  -0.48509
 -0.166679  -0.345137  -0.57188     0.725294</code></pre><p>Let&#39;s plot our results for the first two <strong>SVs</strong>, as we did before. However, this time we will take the knowledge of the different species into account. </p><pre><code class="language-julia hljs"> var_exp = diag(D) ./ sum(D) # variance explained
 Y_tr = data[ind_tr .== 1,&quot;Species&quot;]
 Y_ts = data[ind_tr .== 0,&quot;Species&quot;]
 scatter(U[:,1],U[:,2],label=[&quot;Setosa&quot; &quot;Versicolor&quot; &quot;Virginica&quot;], group = Y_tr)
 xlabel!(&quot;First Singular value (81%)&quot;)
 ylabel!(&quot;Second Singular value (14%)&quot;)</code></pre><img src="660ddd35.svg" alt="Example block output"/><p>As it can be seen, this model is very similar to our previous model based on the full dataset. Now we need to first define thresholds for each class based on the score values in the <span>$U1$</span> and <span>$U2$</span> space. This is typically more difficult to assess. However, for this case the main separating factor is the <span>$U2$</span> values (e.g. <span>$U2 \geq 0.05 = Setosa$</span>). </p><pre><code class="language-julia hljs"> scatter(U[:,1],U[:,2],label=[&quot;Setosa&quot; &quot;Versicolor&quot; &quot;Virginica&quot;], group = Y_tr)
 plot!([-0.15,0],[0.05,0.05],label=&quot;Setosa&quot;)
 plot!([-0.15,0],[-0.04,-0.04],label=&quot;Virginica&quot;)
 xlabel!(&quot;First Singular value (81%)&quot;)
 ylabel!(&quot;Second Singular value (14%)&quot;)</code></pre><img src="6bdc5782.svg" alt="Example block output"/><p>The next step is to calculate the score values for the measurements in the test set. This will enable us to estimate the class associated with each data point in the test set. To do this we need to do a little bit of linear algebra.</p><p class="math-container">\[X = UDV^{T}\\

U_{test} = X \times (DV^{T})^{-1}
\]</p><p>In practice:</p><pre><code class="language-julia hljs"> U_test = X_ts * pinv(D*transpose(V))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">15×4 Matrix{Float64}:
 -0.103478   -0.0632166   -0.0240517    0.0873403
 -0.0793334  -0.0607373   -0.12394     -0.0748002
 -0.0660864   0.115159    -0.0842763    0.0937724
 -0.116258   -0.0957192    0.0815699   -0.0595925
 -0.0713149  -0.00168426   0.0668336    0.0265074
 -0.0574532   0.116261    -0.0398912   -0.0466252
 -0.102862   -0.0825563   -0.089408    -0.0128413
 -0.094306   -0.00983791  -0.00729906  -0.00195828
 -0.071178   -0.0195597    0.124647     0.0305106
 -0.0876516  -0.0119686   -0.0377488    0.0224395
 -0.0851982  -0.0325578   -0.115334    -0.158099
 -0.0834774  -0.0120584    0.0821874    0.0132148
 -0.064962    0.104333    -0.0277708   -0.173327
 -0.121183   -0.0746677   -0.0826052   -0.184155
 -0.0546899   0.0871044    0.137994     0.191674</code></pre><pre><code class="language-julia hljs"> scatter(U[:,1],U[:,2],label=[&quot;Setosa&quot; &quot;Versicolor&quot; &quot;Virginica&quot;], group = Y_tr)
 plot!([-0.15,0],[0.05,0.05],label=&quot;Setosa&quot;)
 plot!([-0.15,0],[-0.04,-0.04],label=&quot;Virginica&quot;)
 scatter!(U_test[Y_ts[:] .== &quot;setosa&quot; ,1],U_test[Y_ts[:] .== &quot;setosa&quot;,2],label=&quot;Setosa&quot;,marker=:d)
 scatter!(U_test[Y_ts[:] .== &quot;versicolor&quot;,1],U_test[Y_ts[:] .== &quot;versicolor&quot;,2],label=&quot;Versicolor&quot;,marker=:d)
 scatter!(U_test[Y_ts[:] .== &quot;virginica&quot;,1],U_test[Y_ts[:] .== &quot;virginica&quot;,2],label=&quot;Virginica&quot;,marker=:d)
 xlabel!(&quot;First Singular value (81%)&quot;)
 ylabel!(&quot;Second Singular value (14%)&quot;)</code></pre><img src="5b8853ff.svg" alt="Example block output"/><p>As it can be seen from the results of the test set, our model is not prefect but it does well for most cases. It should be noted that steps such as data pre-treatment and the use of supervised methods may improve the results of your cluster analysis. The use of <strong>SVD</strong> for prediction is not recommended. It must be mainly used for the dimension reduction and data exploration.  </p><h3 id="Regression"><a class="docs-heading-anchor" href="#Regression">Regression</a><a id="Regression-1"></a><a class="docs-heading-anchor-permalink" href="#Regression" title="Permalink"></a></h3><p>If you have a dataset (e.g. octane dataset in the additional example), where the <strong>SVD</strong> is used to reduce the dimensions of the dataset. In this case the we can perform a least square regression using the selected columns of <span>$U$</span> rather than the original <span>$X$</span>. For example in case of <em>iris</em> dataset the <span>$U1$</span> and <span>$U2$</span> can be used to replace <span>$X$</span>.  </p><pre><code class="language-julia hljs"> X_svr = U[:,1:m] # m is the number of selected SVs 
 Y_svr            # does not exist for iris dataset. for the octane dataset is the octane column
 b = pinv(transpose(X_svr) * X_svr) * transpose(X_svr) * Y_svr # simple least square solution
 y_hat = X_svr * b # prediction the y_hat </code></pre><h3 id="Trend-Analysis"><a class="docs-heading-anchor" href="#Trend-Analysis">Trend Analysis</a><a id="Trend-Analysis-1"></a><a class="docs-heading-anchor-permalink" href="#Trend-Analysis" title="Permalink"></a></h3><p>We also can assess the trend represented by each <em>SV</em> in our model. This is typically done by setting all <em>SV</em> values except one to zero. Then the new <span>$D$</span> is used to predict <span>$\hat{X}$</span>. Then different variables are plotted against each other for both <span>$X$</span> matrices. </p><pre><code class="language-julia hljs"> D_temp = out.S
 D_temp[2:end] .= 0
 D_n = diagm(D_temp) # the new singular value matrix</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">4×4 Matrix{Float64}:
 91.0141  0.0  0.0  0.0
  0.0     0.0  0.0  0.0
  0.0     0.0  0.0  0.0
  0.0     0.0  0.0  0.0</code></pre><p>Then the <span>$\hat{X}$</span> is calculated.</p><pre><code class="language-julia hljs"> X_h  = U * D_n * transpose(V)
 X_h[1:5,:]</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">5×4 Matrix{Float64}:
 4.4566   2.25951  3.02025  0.98697
 4.19972  2.12927  2.84616  0.930079
 4.10548  2.08149  2.78229  0.909209
 4.09689  2.07713  2.77647  0.907307
 4.42868  2.24535  3.00132  0.980785</code></pre><p>Now if we plot the SepalLength vs SepalWidth we can clearly see a clear 1 to 2 relationship between the two variables which is being detected by the first <em>SV</em>. This can be done for other variables and <em>SVs</em>. </p><pre><code class="language-julia hljs"> scatter(X[:,1],X[:,2],label=&quot;X&quot;)
 scatter!(X_h[:,1],X_h[:,2],label=&quot;X_h&quot;)
 xlabel!(&quot;SepalLength&quot;)
 ylabel!(&quot;SepalWidth&quot;)</code></pre><img src="dab7a981.svg" alt="Example block output"/><h2 id="Additional-Example"><a class="docs-heading-anchor" href="#Additional-Example">Additional Example</a><a id="Additional-Example-1"></a><a class="docs-heading-anchor-permalink" href="#Additional-Example" title="Permalink"></a></h2><p>If you are interested in practicing more, you can use the <a href="https://github.com/EMCMS/AdvChemStat.jl/blob/main/datasets/NIR.csv">NIR.csv</a> file provided in the <a href="https://github.com/EMCMS/AdvChemStat.jl/tree/main/datasets">folder dataset</a> of the package <a href="https://github.com/EMCMS/AdvChemStat.jl"><em>AdvChemStat.jl</em> github repository</a>. Please note that this is an <em>SVR</em> problem, where you can first use <strong>SVD</strong> for the dimension reduction and then use the selected <em>SVs</em> for the regression. </p><p>If you are interested in math behind <strong>SVD</strong> and would like to know more you can check this <a href="https://ocw.mit.edu/courses/18-065-matrix-methods-in-data-analysis-signal-processing-and-machine-learning-spring-2018/resources/lecture-6-singular-value-decomposition-svd/">MIT course material</a>.  </p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><a class="docs-footer-nextpage" href="../HCA/">HCA »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.2.1 on <span class="colophon-date" title="Friday 26 January 2024 18:18">Friday 26 January 2024</span>. Using Julia version 1.6.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
